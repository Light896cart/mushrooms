{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import import_ipynb\n",
    "from dataset import DataMushroom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torchvision.transforms import ToTensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "СУПЕР ОСНОВНОЙ X\n",
      "                                                habitat  \\\n",
      "0     Mixed woodland (with coniferous and deciduous ...   \n",
      "1                                                garden   \n",
      "2                                                garden   \n",
      "3                                                garden   \n",
      "4                                                garden   \n",
      "...                                                 ...   \n",
      "7814                                 Deciduous woodland   \n",
      "7815                                 Deciduous woodland   \n",
      "7816                       Unmanaged deciduous woodland   \n",
      "7817                                        salt meadow   \n",
      "7818                                        salt meadow   \n",
      "\n",
      "                       substrate  elevation  landcover biogeographicalRegion  \\\n",
      "0     dead wood (including bark)        0.0       16.0           continental   \n",
      "1     dead wood (including bark)        0.0       17.0           continental   \n",
      "2     dead wood (including bark)        0.0       17.0           continental   \n",
      "3     dead wood (including bark)        0.0       17.0           continental   \n",
      "4     dead wood (including bark)        0.0       17.0           continental   \n",
      "...                          ...        ...        ...                   ...   \n",
      "7814   stems of herbs, grass etc       93.0        1.0           continental   \n",
      "7815   stems of herbs, grass etc       93.0        1.0           continental   \n",
      "7816  dead wood (including bark)        0.0       17.0           continental   \n",
      "7817                     insects        0.0       17.0           continental   \n",
      "7818                     insects        0.0       17.0           continental   \n",
      "\n",
      "      observationID          filename  \n",
      "0        3052832307  0-3052832307.JPG  \n",
      "1        3061954303  0-3061954303.JPG  \n",
      "2        3061954303  1-3061954303.JPG  \n",
      "3        3061954303  2-3061954303.JPG  \n",
      "4        3061954303  3-3061954303.JPG  \n",
      "...             ...               ...  \n",
      "7814     4100093368  0-4100093368.JPG  \n",
      "7815     4100093368  2-4100093368.JPG  \n",
      "7816     3429079314  2-3429079314.JPG  \n",
      "7817     4847339663  0-4847339663.JPG  \n",
      "7818     4847339663  1-4847339663.JPG  \n",
      "\n",
      "[7819 rows x 7 columns]\n",
      "СУПЕР ОСНОВНОЙ Y\n",
      "       kingdom         phylum               class  category_id\n",
      "0        Fungi     Ascomycota      Eurotiomycetes         2421\n",
      "1     Protozoa      Mycetozoa         Myxomycetes          386\n",
      "2     Protozoa      Mycetozoa         Myxomycetes          386\n",
      "3     Protozoa      Mycetozoa         Myxomycetes          386\n",
      "4     Protozoa      Mycetozoa         Myxomycetes          386\n",
      "...        ...            ...                 ...          ...\n",
      "7814     Fungi     Ascomycota     Sordariomycetes         1736\n",
      "7815     Fungi     Ascomycota     Sordariomycetes         1736\n",
      "7816     Fungi  Basidiomycota      Agaricomycetes         1465\n",
      "7817     Fungi     Ascomycota  Laboulbeniomycetes         1166\n",
      "7818     Fungi     Ascomycota  Laboulbeniomycetes         1166\n",
      "\n",
      "[7819 rows x 4 columns]\n",
      "ОСНОВНОЙ X\n",
      "      habitat  substrate  elevation  landcover  biogeographicalRegion\n",
      "0           4          6        0.0       16.0                      4\n",
      "1          15          6        0.0       17.0                      4\n",
      "2          15          6        0.0       17.0                      4\n",
      "3          15          6        0.0       17.0                      4\n",
      "4          15          6        0.0       17.0                      4\n",
      "...       ...        ...        ...        ...                    ...\n",
      "7814        2         27       93.0        1.0                      4\n",
      "7815        2         27       93.0        1.0                      4\n",
      "7816        7          6        0.0       17.0                      4\n",
      "7817       29         11        0.0       17.0                      4\n",
      "7818       29         11        0.0       17.0                      4\n",
      "\n",
      "[7819 rows x 5 columns]\n",
      "ОСНОВНОЙ Y\n",
      "      kingdom  phylum  class\n",
      "0           1       1     11\n",
      "1           2       8     21\n",
      "2           2       8     21\n",
      "3           2       8     21\n",
      "4           2       8     21\n",
      "...       ...     ...    ...\n",
      "7814        1       1     27\n",
      "7815        1       1     27\n",
      "7816        1       2      0\n",
      "7817        1       1     15\n",
      "7818        1       1     15\n",
      "\n",
      "[7819 rows x 3 columns]\n",
      "НЕ ОСНОВНОЙ X\n",
      "      habitat  substrate  elevation  landcover  biogeographicalRegion\n",
      "0           4          6        0.0       16.0                      4\n",
      "1          15          6        0.0       17.0                      4\n",
      "2          15          6        0.0       17.0                      4\n",
      "3          15          6        0.0       17.0                      4\n",
      "4          15          6        0.0       17.0                      4\n",
      "...       ...        ...        ...        ...                    ...\n",
      "7814        2         27       93.0        1.0                      4\n",
      "7815        2         27       93.0        1.0                      4\n",
      "7816        7          6        0.0       17.0                      4\n",
      "7817       29         11        0.0       17.0                      4\n",
      "7818       29         11        0.0       17.0                      4\n",
      "\n",
      "[7819 rows x 5 columns]\n",
      "НЕ ОСНОВНОЙ Y\n",
      "      kingdom  phylum  class\n",
      "0           1       1     11\n",
      "1           2       8     21\n",
      "2           2       8     21\n",
      "3           2       8     21\n",
      "4           2       8     21\n",
      "...       ...     ...    ...\n",
      "7814        1       1     27\n",
      "7815        1       1     27\n",
      "7816        1       2      0\n",
      "7817        1       1     15\n",
      "7818        1       1     15\n",
      "\n",
      "[7819 rows x 3 columns]\n",
      "ПОСЛЕ ОБРАБОТКИ X\n",
      "      habitat  substrate  elevation  landcover  biogeographicalRegion\n",
      "0           4          6        0.0       16.0                      4\n",
      "1          15          6        0.0       17.0                      4\n",
      "2          15          6        0.0       17.0                      4\n",
      "3          15          6        0.0       17.0                      4\n",
      "4          15          6        0.0       17.0                      4\n",
      "...       ...        ...        ...        ...                    ...\n",
      "7814        2         27       93.0        1.0                      4\n",
      "7815        2         27       93.0        1.0                      4\n",
      "7816        7          6        0.0       17.0                      4\n",
      "7817       29         11        0.0       17.0                      4\n",
      "7818       29         11        0.0       17.0                      4\n",
      "\n",
      "[7819 rows x 5 columns]\n",
      "ПОСЛЕ ОБРАБОТКИ Y\n",
      "      kingdom  phylum  class\n",
      "0           1       1     11\n",
      "1           2       8     21\n",
      "2           2       8     21\n",
      "3           2       8     21\n",
      "4           2       8     21\n",
      "...       ...     ...    ...\n",
      "7814        1       1     27\n",
      "7815        1       1     27\n",
      "7816        1       2      0\n",
      "7817        1       1     15\n",
      "7818        1       1     15\n",
      "\n",
      "[7819 rows x 3 columns]\n",
      "<dataset.DataMushroom object at 0x00000272BDB16FE0>\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('E:\\jupyter\\Грибы\\metadata\\FungiTastic-FewShot\\FungiTastic-FewShot-Train.csv')\n",
    "# Выбор входных параметров X\n",
    "X = df[['habitat', 'substrate', 'elevation', 'landcover', 'biogeographicalRegion', 'observationID','filename']]\n",
    "# Выбор выходных параметров y \n",
    "y = df[['kingdom', 'phylum', 'class','category_id']]\n",
    "data = DataMushroom(X,y)\n",
    "print(data)\n",
    "# Создаем загрузчик данных\n",
    "train_loader = DataLoader(data, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 10, 3, 224, 224])\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\jupyter\\Грибы\\dataset.py:160\u001b[0m, in \u001b[0;36mDataMushroom.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    150\u001b[0m sample \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_data\u001b[39m\u001b[38;5;124m'\u001b[39m: x_tensor,\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# 'filenames': patch_filenames.tolist(),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages_tensor\u001b[39m\u001b[38;5;124m'\u001b[39m: images_tensor\n\u001b[0;32m    156\u001b[0m }\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_y\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Получаем токенизированные метки и category_id\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m     y_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_y\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobs_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    161\u001b[0m     category_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategory_ids[obs_mask]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Убедимся что все тензоры одинакового размера\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4151\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4147\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[0;32m   4148\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[0;32m   4149\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[1;32m-> 4151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4154\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_core\\_methods.py:74\u001b[0m, in \u001b[0;36m_all\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for c in train_loader:\n",
    "    print(c['x_data'].shape)\n",
    "    print(c['y_data'].shape)\n",
    "    print(c['images_tensor'].shape)\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,c in enumerate(train_loader):\n",
    "#     print(f\"X_data shape: {c['x_data'].shape}\")\n",
    "#     print(f\"y_data shape: {c['y_data'].shape}\")\n",
    "#     print(f\"img shape: {c['images_tensor'].shape}\")\n",
    "#     print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Столбец 0: 33 уникальных значений\n",
      "Столбец 1: 3 уникальных значений\n",
      "Столбец 2: 11 уникальных значений\n",
      "Столбец 3: 2427 уникальных значений\n"
     ]
    }
   ],
   "source": [
    "unique_counts = {}\n",
    "for c in data:\n",
    "    y = c['y_data']\n",
    "    # Обрабатываем все столбцы\n",
    "    for col in range(y.shape[0]):\n",
    "        unique_vals = torch.unique(y[col])\n",
    "        if col not in unique_counts:\n",
    "            unique_counts[col] = set()\n",
    "        unique_counts[col].update(unique_vals.tolist())\n",
    "        \n",
    "unique_counts[0], unique_counts[3] = unique_counts[3], unique_counts[0]\n",
    "for col, vals in unique_counts.items():\n",
    "    print(f\"Столбец {col}: {len(vals)} уникальных значений\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Столбец 0: 33 уникальных значений\n",
      "Столбец 1: 3 уникальных значений\n",
      "Столбец 2: 11 уникальных значений\n",
      "Столбец 3: 2427 уникальных значений\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col, vals in unique_counts.items():\n",
    "    print(f\"Столбец {col}: {len(vals)} уникальных значений\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Архитектура ResNet18:\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Загружаем предобученную модель ResNet18\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "# Удаляем все слои после layer4\n",
    "model = nn.Sequential(*list(model.children())[:-2])\n",
    "\n",
    "# Выводим структуру модели\n",
    "print(\"Архитектура ResNet18:\")\n",
    "print(model)\n",
    "\n",
    "# Замораживаем веса предобученной модели\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обновленная архитектура модели:\n",
      "CustomResNet(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (attention): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (fc_after_attention): Sequential(\n",
      "    (0): Linear(in_features=513, out_features=384, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (7): Linear(in_features=256, out_features=512, bias=True)\n",
      "  )\n",
      "  (parameters_net): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=256, out_features=512, bias=True)\n",
      "  )\n",
      "  (final_layers): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=768, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=256, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Сначала очищаем предыдущую модель\n",
    "model = resnet18(pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-2])\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.cnn = (\n",
    "            base_model.cnn if isinstance(base_model, CustomResNet)\n",
    "            else nn.Sequential(\n",
    "                *list(base_model),\n",
    "                nn.AdaptiveAvgPool2d((1, 1))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        self.fc_after_attention = nn.Sequential(\n",
    "            nn.Linear(513, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(384),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(384, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(256, 512)\n",
    "        )\n",
    "        \n",
    "        self.parameters_net = nn.Sequential(\n",
    "            nn.Linear(5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512)\n",
    "        )\n",
    "        \n",
    "        self.final_layers = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.Linear(1024, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 4)  # Выходной слой под формат [2193, 1, 1, 17]\n",
    "        )\n",
    "\n",
    "    def hierarchical_structure(self, parameter, img_feature):\n",
    "        parameter = parameter.float()\n",
    "        expanded_param = parameter[:img_feature.size(0), 0].unsqueeze(1)\n",
    "        combined_features = torch.cat([img_feature, expanded_param], dim=1)\n",
    "        return self.fc_after_attention(combined_features)\n",
    "\n",
    "    def attention_function(self, attention_weights):\n",
    "        batch_size, num_images, channels, height, width = attention_weights.size()\n",
    "        attention_weights = attention_weights.view(batch_size * num_images, channels, height, width)\n",
    "        img_features = self.cnn(attention_weights)\n",
    "        img_features = img_features.view(batch_size, -1, 512)\n",
    "        attention_weights = self.attention(img_features)\n",
    "        attention_weights = F.softmax(attention_weights, dim=1)\n",
    "        weighted_features = attention_weights * img_features\n",
    "        return weighted_features.sum(dim=1)\n",
    "\n",
    "    def forward(self, img, parameters):\n",
    "        if isinstance(img, list):\n",
    "            img = torch.stack(img).unsqueeze(0)\n",
    "        \n",
    "        img_features = self.attention_function(img)\n",
    "        atten = self.hierarchical_structure(parameters, img_features)\n",
    "        \n",
    "        # print(f'НОРМ {atten.shape}')\n",
    "        # # Обработка через final_layers для получения нужного формата выхода\n",
    "        # parameters_features = self.parameters_net(parameters)\n",
    "        # print(f'СУПЕР ВАЖНО {parameters_features.shape}')\n",
    "        # combined = torch.cat([atten, parameters_features], dim=1)\n",
    "        output = self.final_layers(atten)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Создаем экземпляр модели только один раз\n",
    "model = CustomResNet(model)\n",
    "\n",
    "print(\"\\nОбновленная архитектура модели:\")\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom(nn.Module):\n",
    "    def __init__(self, base_model, unique_counts):\n",
    "        super().__init__()\n",
    "        self.unique_counts = unique_counts\n",
    "        \n",
    "        # GPU-optimized attention layers\n",
    "        self.attention_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(513 + i, 256 + i),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256 + i, 513 + i)\n",
    "            ).cuda() for i in range(5)\n",
    "        ])\n",
    "\n",
    "        # GPU-optimized CNN\n",
    "        self.cnn = nn.Sequential(\n",
    "            *list(base_model),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        ).cuda()\n",
    "        \n",
    "        # GPU-optimized attention\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        ).cuda()\n",
    "        \n",
    "        # GPU-optimized output layer\n",
    "        self.outlayer = nn.Sequential(\n",
    "            nn.Linear(517, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.ReLU()\n",
    "        ).cuda()\n",
    "\n",
    "    def atteintion_img_patch(self, img_patch):\n",
    "        img_patch = img_patch.cuda()\n",
    "        batch, num_img, channels, width, height = img_patch.size()\n",
    "        features_img = img_patch.view(batch*num_img, channels, width, height)\n",
    "        features_img_cnn = self.cnn(features_img)\n",
    "        \n",
    "        prepared_features = features_img_cnn.view(batch, -1, 512)\n",
    "        attention_feature = self.attention(prepared_features)\n",
    "        attention_softmax = F.softmax(attention_feature, dim=1)\n",
    "        \n",
    "        attention_weight = prepared_features * attention_softmax\n",
    "        return attention_weight.sum(dim=1)\n",
    "\n",
    "    def additional_parameters(self, x_param, attention_img_features, i):\n",
    "        if i == 5:\n",
    "            return attention_img_features\n",
    "        x_param = x_param.cuda()\n",
    "        unification = torch.cat((attention_img_features, x_param.T[i].view(-1,1)), dim=1)\n",
    "        attention_img_features = self.attention_layers[i](unification)\n",
    "        if i < 4:\n",
    "            hierarchy_output = nn.Linear(attention_img_features.size(1), len(self.unique_counts[i])).cuda()(attention_img_features)\n",
    "            self.ouputs.append(hierarchy_output)\n",
    "        return self.additional_parameters(x_param, attention_img_features, i+1)\n",
    "\n",
    "    def forward(self, img_patch, parameters):\n",
    "        self.ouputs = []\n",
    "        attention_img = self.atteintion_img_patch(img_patch)\n",
    "        reg = self.additional_parameters(parameters, attention_img, 0)\n",
    "        x = self.outlayer(reg)\n",
    "        return x, self.ouputs\n",
    "\n",
    "resnet = resnet18(pretrained=True).cuda()\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-2])\n",
    "model = Custom(resnet, unique_counts).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom(\n",
      "  (attention_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=513, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=513, bias=True)\n",
      "      (4): Linear(in_features=513, out_features=513, bias=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=514, out_features=257, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=257, out_features=514, bias=True)\n",
      "      (4): Linear(in_features=514, out_features=514, bias=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=515, out_features=258, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=258, out_features=515, bias=True)\n",
      "      (4): Linear(in_features=515, out_features=515, bias=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=516, out_features=259, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=259, out_features=516, bias=True)\n",
      "      (4): Linear(in_features=516, out_features=516, bias=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=517, out_features=260, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=260, out_features=517, bias=True)\n",
      "      (4): Linear(in_features=517, out_features=517, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (attention): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      "  (outlayer): Sequential(\n",
      "    (0): Linear(in_features=517, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      6\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      8\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      9\u001b[0m         img \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages_tensor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\jupyter\\Грибы\\dataset.py:143\u001b[0m, in \u001b[0;36mDataMushroom.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    140\u001b[0m images_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(max_patches, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(max_patches, \u001b[38;5;28mlen\u001b[39m(patch_filenames))):\n\u001b[1;32m--> 143\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mE:/jupyter/Грибы/images/images/train/300p/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpatch_filenames\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     images_tensor[i] \u001b[38;5;241m=\u001b[39m transform(img)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Преобразуем x_data в матрицу нужной формы\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3466\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3464\u001b[0m filename: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[1;32m-> 3466\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m   3469\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ntpath.py:689\u001b[0m, in \u001b[0;36mrealpath\u001b[1;34m(path, strict)\u001b[0m\n\u001b[0;32m    687\u001b[0m     path \u001b[38;5;241m=\u001b[39m join(cwd, path)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 689\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43m_getfinalpathname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m     initial_winerror \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for d in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        img = d['images_tensor']\n",
    "        x_data = d['x_data']\n",
    "        y_data = d['y_data']\n",
    "\n",
    "        output,ouputs = model(img, x_data)\n",
    "        weights = [1/2427, 1/3, 1/11, 1/33]\n",
    "        total_loss = 0\n",
    "        for level in range(len(ouputs)):\n",
    "            print('OUTPUT',ouputs[0])\n",
    "            print('Y_DATA',y_data.T[level].long())\n",
    "            loss = criterion(ouputs[level], y_data.T[level].long())\n",
    "            loss.backward(retain_graph=True)\n",
    "            # optimizer.step()\n",
    "            total_loss += loss * weights[level]\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        print(total_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'topk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m output \u001b[38;5;241m=\u001b[39m model(img, x_data)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Проверяем, есть ли правильный класс в топ-5 предсказаний\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m top5 \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m(\u001b[38;5;241m5\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_data \u001b[38;5;129;01min\u001b[39;00m top5:\n\u001b[0;32m     33\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, device\u001b[38;5;241m=\u001b[39moutput\u001b[38;5;241m.\u001b[39mdevice, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Добавляем requires_grad\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'topk'"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "# Изменяем выходной слой для 32 классов\n",
    "model.outlayer = nn.Sequential(\n",
    "    nn.Linear(517, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 2426)  # 32 класса\n",
    ")\n",
    "\n",
    "# Для графика\n",
    "epoch_losses = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for d in data:\n",
    "        optimizer.zero_grad()\n",
    "        img = d['images_tensor']\n",
    "        x_data = d['x_data']\n",
    "        y_data = d['y_data'].T[:,0][0].view(-1).long()\n",
    "        \n",
    "        # Проверка на корректность меток\n",
    "        if y_data.max() >= 2426 or y_data.min() < 0:\n",
    "            print(f\"Пропуск батча с некорректными метками: {y_data}\")\n",
    "            continue\n",
    "            \n",
    "        output,ouputs = model(img, x_data)\n",
    "        \n",
    "        # Проверяем, есть ли правильный класс в топ-5 предсказаний\n",
    "        top5 = output.topk(5)[1]\n",
    "        if y_data in top5:\n",
    "            loss = torch.tensor(0.0, device=output.device, requires_grad=True)  # Добавляем requires_grad\n",
    "        else:\n",
    "            loss = criterion(output, y_data)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_value = loss.item()\n",
    "        print(f'y_data: {y_data[0].item()}, output: {output.argmax(1)[0].item()}, top5: {top5[0].tolist()}, loss: {loss_value}')\n",
    "        epoch_losses.append(loss.detach())  # Сохраняем без градиентов\n",
    "    # print(f'Epoch {epoch+1}, Avg Loss: {avg_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализуем потери через softmax\n",
    "import torch.nn.functional as F\n",
    "epoch_losses = torch.sigmoid(torch.tensor(epoch_losses)).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Рисуем график, исключая loss = 5\n",
    "import matplotlib.pyplot as plt\n",
    "filtered_losses = [loss.detach().numpy() for loss in epoch_losses if loss.detach().numpy() < 5.0]\n",
    "plt.plot(range(len(filtered_losses)), filtered_losses)\n",
    "plt.xlabel('Шаг обучения')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('График потерь (без clipped значений)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма тензора: torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Определяем гиперпараметры\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4210e+03, 1.0000e+00, 1.0000e+00, 1.1000e+01]])\n",
      "attention_weight_sum tensor([[0.9221, 0.9338, 0.9053, 0.9701, 0.9988, 0.8823, 0.8948, 1.1779, 0.9717,\n",
      "         0.9679, 0.9024, 0.8307, 0.9903, 0.8833, 0.9465, 0.9499, 0.9226, 1.3537,\n",
      "         0.9604, 0.8125, 0.8879, 1.0807, 0.9117, 1.0665, 0.8951, 0.9524, 0.9796,\n",
      "         1.0217, 0.8870, 0.8555, 0.9506, 0.7839, 0.9691, 0.8803, 0.9253, 0.8467,\n",
      "         0.9327, 0.9498, 0.8964, 0.9186, 0.8804, 0.9053, 0.8538, 0.9378, 0.8401,\n",
      "         0.8704, 0.8906, 1.0982, 0.9733, 0.8903, 0.9285, 0.9045, 0.8441, 0.8155,\n",
      "         0.9591, 0.9593, 1.1689, 0.8739, 0.9164, 1.0017, 0.8581, 0.9437, 0.9847,\n",
      "         0.9815, 0.7418, 0.9707, 0.8157, 0.8546, 1.0004, 0.8961, 0.9282, 0.8297,\n",
      "         0.9326, 0.8839, 0.9151, 0.8379, 0.9304, 0.8977, 0.9331, 0.8457, 0.9174,\n",
      "         1.0339, 1.0753, 1.2782, 0.8392, 0.9522, 0.9563, 0.7447, 0.8987, 0.8243,\n",
      "         0.8010, 0.9563, 0.8891, 0.8457, 0.8275, 0.8315, 0.9713, 0.9438, 0.8993,\n",
      "         0.8661, 1.0673, 1.0087, 0.9562, 1.0208, 0.9176, 0.7648, 0.9722, 0.8944,\n",
      "         0.9303, 0.9241, 0.8981, 0.9592, 0.8074, 0.9029, 0.8896, 0.9132, 0.8759,\n",
      "         0.9205, 0.9104, 0.9490, 0.9566, 0.9848, 0.9201, 0.8332, 0.9166, 0.8020,\n",
      "         0.9286, 0.9615, 0.9345, 0.9879, 0.8758, 0.8154, 0.8336, 0.9737, 1.0730,\n",
      "         0.9929, 0.8234, 1.0155, 0.8967, 0.8763, 0.9124, 0.9060, 0.9920, 0.9231,\n",
      "         0.9138, 0.8695, 0.7977, 0.9205, 0.9318, 1.0330, 0.8927, 0.8406, 0.9026,\n",
      "         0.8854, 0.8368, 0.8419, 0.9678, 0.9603, 0.8772, 0.8558, 0.9250, 1.2628,\n",
      "         0.9921, 1.2692, 0.9804, 0.9981, 0.9843, 0.9052, 1.0369, 0.9105, 0.9510,\n",
      "         0.7343, 0.8143, 0.9034, 0.8994, 0.9232, 0.9680, 0.8480, 1.1396, 0.8392,\n",
      "         0.9087, 0.9597, 1.1974, 0.8886, 1.0499, 1.0048, 0.9160, 1.0326, 0.8560,\n",
      "         0.8627, 0.8626, 0.8281, 0.9326, 1.0828, 0.8605, 0.8647, 1.0065, 0.8555,\n",
      "         0.8836, 0.9072, 0.8227, 0.8572, 1.0820, 0.8975, 1.0565, 0.9262, 0.8884,\n",
      "         0.9154, 0.9313, 1.0568, 0.8049, 0.8681, 0.8732, 0.9517, 1.0051, 0.8949,\n",
      "         0.8709, 0.8682, 0.7985, 1.0210, 0.9608, 1.0210, 0.8880, 0.9298, 0.8938,\n",
      "         0.8543, 1.0097, 0.9164, 1.0312, 0.9047, 0.9082, 0.9153, 0.8634, 0.9609,\n",
      "         0.8225, 0.9075, 0.9843, 0.9866, 0.8964, 1.0607, 0.8303, 0.9110, 0.9842,\n",
      "         0.8787, 0.9507, 0.9816, 1.0197, 0.7661, 0.9628, 0.9981, 1.0845, 0.9327,\n",
      "         1.0319, 0.9582, 0.9941, 1.1783, 0.9345, 1.0894, 0.9913, 1.0399, 0.9428,\n",
      "         0.9234, 0.9334, 0.9604, 0.9703, 0.8436, 0.9031, 0.9455, 0.8140, 0.8776,\n",
      "         0.8873, 0.8319, 0.9173, 0.8745, 0.9920, 0.8981, 0.9928, 0.8965, 0.9091,\n",
      "         0.8964, 1.2984, 0.8102, 0.8965, 0.8789, 1.0147, 0.8742, 0.9540, 0.8555,\n",
      "         1.0743, 0.8748, 0.9408, 0.7961, 0.8211, 0.9123, 0.9486, 0.8557, 0.8689,\n",
      "         1.1674, 0.8778, 0.9069, 0.8234, 0.8831, 0.8235, 0.8778, 1.0441, 0.9778,\n",
      "         0.9385, 0.9098, 0.8492, 0.8939, 1.0292, 0.9829, 1.0575, 0.9031, 0.8488,\n",
      "         0.9047, 0.9994, 0.9052, 1.0608, 0.9652, 0.9912, 0.9555, 0.9507, 0.9433,\n",
      "         0.8267, 0.8966, 0.9861, 0.8924, 0.8974, 0.8484, 1.0204, 1.0486, 0.9393,\n",
      "         0.9212, 0.9656, 0.8563, 1.0248, 0.9542, 1.0178, 0.9316, 0.8301, 0.9504,\n",
      "         0.8883, 1.1000, 0.9761, 0.8462, 0.9115, 0.9006, 0.8622, 0.9955, 0.9471,\n",
      "         0.9496, 0.9134, 0.9078, 0.8976, 0.8716, 0.8946, 0.9857, 0.8813, 0.8730,\n",
      "         0.9400, 0.9612, 0.8399, 0.8538, 0.9574, 0.9275, 0.9294, 0.9294, 0.9388,\n",
      "         0.8270, 1.0844, 0.9056, 1.0348, 0.9568, 0.8676, 0.8484, 0.9162, 0.8464,\n",
      "         0.9647, 0.8954, 1.0411, 0.9129, 0.9223, 0.9729, 1.1221, 1.0009, 0.7957,\n",
      "         1.0149, 0.8118, 1.0093, 0.9595, 0.9135, 0.9167, 1.0048, 1.0839, 0.9448,\n",
      "         0.8714, 0.9476, 0.9547, 0.9652, 1.1274, 1.1514, 0.8272, 0.8610, 0.9608,\n",
      "         0.8847, 0.9547, 0.9606, 0.9458, 0.8821, 0.9033, 0.9141, 0.9010, 0.8399,\n",
      "         0.9605, 0.8897, 0.9217, 0.9196, 0.9009, 0.9093, 0.9214, 0.9001, 0.9267,\n",
      "         0.9133, 0.9452, 0.9042, 0.9543, 1.1042, 0.9548, 0.9650, 0.9587, 0.9049,\n",
      "         0.8412, 0.8305, 1.0197, 1.1003, 0.8873, 0.9319, 0.9795, 0.8289, 0.8610,\n",
      "         0.8854, 0.9479, 0.9249, 0.9625, 0.9132, 1.0702, 0.9171, 1.0245, 0.9278,\n",
      "         0.8794, 0.9590, 0.9335, 0.8436, 0.8671, 0.9492, 0.8370, 0.9360, 0.8694,\n",
      "         0.8957, 1.1623, 0.8357, 0.9010, 0.8453, 0.9914, 0.9083, 0.9516, 0.8808,\n",
      "         0.9692, 0.8620, 0.9622, 0.9672, 0.8979, 0.8688, 0.8597, 0.8210, 0.8618,\n",
      "         0.9097, 0.8698, 0.9535, 0.8436, 0.9559, 0.9143, 0.9234, 1.1471, 0.9568,\n",
      "         1.0103, 1.0469, 1.0938, 0.8346, 1.0208, 1.0450, 0.9535, 0.9617, 0.8557,\n",
      "         0.9138, 0.8779, 0.8202, 0.9798, 0.9039, 1.0165, 0.8781, 0.9398, 0.9330,\n",
      "         0.8993, 0.7636, 1.0690, 1.0144, 0.9345, 0.9141, 1.0671, 0.9229]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "attention_weight_sum torch.Size([1, 512])\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(img, x_train)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Вычисляем функцию потерь\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Обратное распространение\u001b[39;00m\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Артём\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for d in data:\n",
    "        x_train = d['x_data']\n",
    "        img = d['images_tensor']\n",
    "        y_data = d['y_data'][0].float().unsqueeze(0)  # Берем только первый экземпляр, преобразуем в float и добавляем размерность\n",
    "        print(y_data)\n",
    "        # Обнуляем градиенты\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Прямой проход\n",
    "        outputs = model(img, x_train)\n",
    "        \n",
    "        # Вычисляем функцию потерь\n",
    "        loss = criterion(outputs, y_data)\n",
    "        \n",
    "        # Обратное распространение\n",
    "        loss.backward()\n",
    "        \n",
    "        # Оптимизация\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        print(running_loss)\n",
    "    \n",
    "    # Выводим среднюю потерю за эпоху\n",
    "    epoch_loss = running_loss / len(data)\n",
    "    print(f'Эпоха {epoch+1}/{num_epochs}, Потери: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходная форма: tensor([[[[ 1.1746]],\n",
      "\n",
      "         [[-1.4089]],\n",
      "\n",
      "         [[-0.3567]]],\n",
      "\n",
      "\n",
      "        [[[-2.0994]],\n",
      "\n",
      "         [[-0.5602]],\n",
      "\n",
      "         [[-0.6238]]],\n",
      "\n",
      "\n",
      "        [[[-0.7796]],\n",
      "\n",
      "         [[ 1.3176]],\n",
      "\n",
      "         [[ 0.4010]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3354]],\n",
      "\n",
      "         [[ 0.9565]],\n",
      "\n",
      "         [[-0.5290]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1972]],\n",
      "\n",
      "         [[ 0.2292]],\n",
      "\n",
      "         [[ 0.5302]]],\n",
      "\n",
      "\n",
      "        [[[-0.3444]],\n",
      "\n",
      "         [[-1.3209]],\n",
      "\n",
      "         [[-1.1173]]],\n",
      "\n",
      "\n",
      "        [[[-1.2505]],\n",
      "\n",
      "         [[-0.2693]],\n",
      "\n",
      "         [[-0.0982]]],\n",
      "\n",
      "\n",
      "        [[[-0.8885]],\n",
      "\n",
      "         [[-0.3858]],\n",
      "\n",
      "         [[ 0.4821]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0204]],\n",
      "\n",
      "         [[-0.0498]],\n",
      "\n",
      "         [[-0.5802]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3428]],\n",
      "\n",
      "         [[ 0.8945]],\n",
      "\n",
      "         [[ 0.5881]]]])\n",
      "Новая форма: tensor([[[[ 1.1746,  1.1746,  1.1746,  ...,  1.1746,  1.1746,  1.1746],\n",
      "          [ 1.1746,  1.1746,  1.1746,  ...,  1.1746,  1.1746,  1.1746],\n",
      "          [ 1.1746,  1.1746,  1.1746,  ...,  1.1746,  1.1746,  1.1746],\n",
      "          ...,\n",
      "          [ 1.1746,  1.1746,  1.1746,  ...,  1.1746,  1.1746,  1.1746],\n",
      "          [ 1.1746,  1.1746,  1.1746,  ...,  1.1746,  1.1746,  1.1746],\n",
      "          [ 1.1746,  1.1746,  1.1746,  ...,  1.1746,  1.1746,  1.1746]],\n",
      "\n",
      "         [[-1.4089, -1.4089, -1.4089,  ..., -1.4089, -1.4089, -1.4089],\n",
      "          [-1.4089, -1.4089, -1.4089,  ..., -1.4089, -1.4089, -1.4089],\n",
      "          [-1.4089, -1.4089, -1.4089,  ..., -1.4089, -1.4089, -1.4089],\n",
      "          ...,\n",
      "          [-1.4089, -1.4089, -1.4089,  ..., -1.4089, -1.4089, -1.4089],\n",
      "          [-1.4089, -1.4089, -1.4089,  ..., -1.4089, -1.4089, -1.4089],\n",
      "          [-1.4089, -1.4089, -1.4089,  ..., -1.4089, -1.4089, -1.4089]],\n",
      "\n",
      "         [[-0.3567, -0.3567, -0.3567,  ..., -0.3567, -0.3567, -0.3567],\n",
      "          [-0.3567, -0.3567, -0.3567,  ..., -0.3567, -0.3567, -0.3567],\n",
      "          [-0.3567, -0.3567, -0.3567,  ..., -0.3567, -0.3567, -0.3567],\n",
      "          ...,\n",
      "          [-0.3567, -0.3567, -0.3567,  ..., -0.3567, -0.3567, -0.3567],\n",
      "          [-0.3567, -0.3567, -0.3567,  ..., -0.3567, -0.3567, -0.3567],\n",
      "          [-0.3567, -0.3567, -0.3567,  ..., -0.3567, -0.3567, -0.3567]]],\n",
      "\n",
      "\n",
      "        [[[-2.0994, -2.0994, -2.0994,  ..., -2.0994, -2.0994, -2.0994],\n",
      "          [-2.0994, -2.0994, -2.0994,  ..., -2.0994, -2.0994, -2.0994],\n",
      "          [-2.0994, -2.0994, -2.0994,  ..., -2.0994, -2.0994, -2.0994],\n",
      "          ...,\n",
      "          [-2.0994, -2.0994, -2.0994,  ..., -2.0994, -2.0994, -2.0994],\n",
      "          [-2.0994, -2.0994, -2.0994,  ..., -2.0994, -2.0994, -2.0994],\n",
      "          [-2.0994, -2.0994, -2.0994,  ..., -2.0994, -2.0994, -2.0994]],\n",
      "\n",
      "         [[-0.5602, -0.5602, -0.5602,  ..., -0.5602, -0.5602, -0.5602],\n",
      "          [-0.5602, -0.5602, -0.5602,  ..., -0.5602, -0.5602, -0.5602],\n",
      "          [-0.5602, -0.5602, -0.5602,  ..., -0.5602, -0.5602, -0.5602],\n",
      "          ...,\n",
      "          [-0.5602, -0.5602, -0.5602,  ..., -0.5602, -0.5602, -0.5602],\n",
      "          [-0.5602, -0.5602, -0.5602,  ..., -0.5602, -0.5602, -0.5602],\n",
      "          [-0.5602, -0.5602, -0.5602,  ..., -0.5602, -0.5602, -0.5602]],\n",
      "\n",
      "         [[-0.6238, -0.6238, -0.6238,  ..., -0.6238, -0.6238, -0.6238],\n",
      "          [-0.6238, -0.6238, -0.6238,  ..., -0.6238, -0.6238, -0.6238],\n",
      "          [-0.6238, -0.6238, -0.6238,  ..., -0.6238, -0.6238, -0.6238],\n",
      "          ...,\n",
      "          [-0.6238, -0.6238, -0.6238,  ..., -0.6238, -0.6238, -0.6238],\n",
      "          [-0.6238, -0.6238, -0.6238,  ..., -0.6238, -0.6238, -0.6238],\n",
      "          [-0.6238, -0.6238, -0.6238,  ..., -0.6238, -0.6238, -0.6238]]],\n",
      "\n",
      "\n",
      "        [[[-0.7796, -0.7796, -0.7796,  ..., -0.7796, -0.7796, -0.7796],\n",
      "          [-0.7796, -0.7796, -0.7796,  ..., -0.7796, -0.7796, -0.7796],\n",
      "          [-0.7796, -0.7796, -0.7796,  ..., -0.7796, -0.7796, -0.7796],\n",
      "          ...,\n",
      "          [-0.7796, -0.7796, -0.7796,  ..., -0.7796, -0.7796, -0.7796],\n",
      "          [-0.7796, -0.7796, -0.7796,  ..., -0.7796, -0.7796, -0.7796],\n",
      "          [-0.7796, -0.7796, -0.7796,  ..., -0.7796, -0.7796, -0.7796]],\n",
      "\n",
      "         [[ 1.3176,  1.3176,  1.3176,  ...,  1.3176,  1.3176,  1.3176],\n",
      "          [ 1.3176,  1.3176,  1.3176,  ...,  1.3176,  1.3176,  1.3176],\n",
      "          [ 1.3176,  1.3176,  1.3176,  ...,  1.3176,  1.3176,  1.3176],\n",
      "          ...,\n",
      "          [ 1.3176,  1.3176,  1.3176,  ...,  1.3176,  1.3176,  1.3176],\n",
      "          [ 1.3176,  1.3176,  1.3176,  ...,  1.3176,  1.3176,  1.3176],\n",
      "          [ 1.3176,  1.3176,  1.3176,  ...,  1.3176,  1.3176,  1.3176]],\n",
      "\n",
      "         [[ 0.4010,  0.4010,  0.4010,  ...,  0.4010,  0.4010,  0.4010],\n",
      "          [ 0.4010,  0.4010,  0.4010,  ...,  0.4010,  0.4010,  0.4010],\n",
      "          [ 0.4010,  0.4010,  0.4010,  ...,  0.4010,  0.4010,  0.4010],\n",
      "          ...,\n",
      "          [ 0.4010,  0.4010,  0.4010,  ...,  0.4010,  0.4010,  0.4010],\n",
      "          [ 0.4010,  0.4010,  0.4010,  ...,  0.4010,  0.4010,  0.4010],\n",
      "          [ 0.4010,  0.4010,  0.4010,  ...,  0.4010,  0.4010,  0.4010]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.8885, -0.8885, -0.8885,  ..., -0.8885, -0.8885, -0.8885],\n",
      "          [-0.8885, -0.8885, -0.8885,  ..., -0.8885, -0.8885, -0.8885],\n",
      "          [-0.8885, -0.8885, -0.8885,  ..., -0.8885, -0.8885, -0.8885],\n",
      "          ...,\n",
      "          [-0.8885, -0.8885, -0.8885,  ..., -0.8885, -0.8885, -0.8885],\n",
      "          [-0.8885, -0.8885, -0.8885,  ..., -0.8885, -0.8885, -0.8885],\n",
      "          [-0.8885, -0.8885, -0.8885,  ..., -0.8885, -0.8885, -0.8885]],\n",
      "\n",
      "         [[-0.3858, -0.3858, -0.3858,  ..., -0.3858, -0.3858, -0.3858],\n",
      "          [-0.3858, -0.3858, -0.3858,  ..., -0.3858, -0.3858, -0.3858],\n",
      "          [-0.3858, -0.3858, -0.3858,  ..., -0.3858, -0.3858, -0.3858],\n",
      "          ...,\n",
      "          [-0.3858, -0.3858, -0.3858,  ..., -0.3858, -0.3858, -0.3858],\n",
      "          [-0.3858, -0.3858, -0.3858,  ..., -0.3858, -0.3858, -0.3858],\n",
      "          [-0.3858, -0.3858, -0.3858,  ..., -0.3858, -0.3858, -0.3858]],\n",
      "\n",
      "         [[ 0.4821,  0.4821,  0.4821,  ...,  0.4821,  0.4821,  0.4821],\n",
      "          [ 0.4821,  0.4821,  0.4821,  ...,  0.4821,  0.4821,  0.4821],\n",
      "          [ 0.4821,  0.4821,  0.4821,  ...,  0.4821,  0.4821,  0.4821],\n",
      "          ...,\n",
      "          [ 0.4821,  0.4821,  0.4821,  ...,  0.4821,  0.4821,  0.4821],\n",
      "          [ 0.4821,  0.4821,  0.4821,  ...,  0.4821,  0.4821,  0.4821],\n",
      "          [ 0.4821,  0.4821,  0.4821,  ...,  0.4821,  0.4821,  0.4821]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0204,  1.0204,  1.0204,  ...,  1.0204,  1.0204,  1.0204],\n",
      "          [ 1.0204,  1.0204,  1.0204,  ...,  1.0204,  1.0204,  1.0204],\n",
      "          [ 1.0204,  1.0204,  1.0204,  ...,  1.0204,  1.0204,  1.0204],\n",
      "          ...,\n",
      "          [ 1.0204,  1.0204,  1.0204,  ...,  1.0204,  1.0204,  1.0204],\n",
      "          [ 1.0204,  1.0204,  1.0204,  ...,  1.0204,  1.0204,  1.0204],\n",
      "          [ 1.0204,  1.0204,  1.0204,  ...,  1.0204,  1.0204,  1.0204]],\n",
      "\n",
      "         [[-0.0498, -0.0498, -0.0498,  ..., -0.0498, -0.0498, -0.0498],\n",
      "          [-0.0498, -0.0498, -0.0498,  ..., -0.0498, -0.0498, -0.0498],\n",
      "          [-0.0498, -0.0498, -0.0498,  ..., -0.0498, -0.0498, -0.0498],\n",
      "          ...,\n",
      "          [-0.0498, -0.0498, -0.0498,  ..., -0.0498, -0.0498, -0.0498],\n",
      "          [-0.0498, -0.0498, -0.0498,  ..., -0.0498, -0.0498, -0.0498],\n",
      "          [-0.0498, -0.0498, -0.0498,  ..., -0.0498, -0.0498, -0.0498]],\n",
      "\n",
      "         [[-0.5802, -0.5802, -0.5802,  ..., -0.5802, -0.5802, -0.5802],\n",
      "          [-0.5802, -0.5802, -0.5802,  ..., -0.5802, -0.5802, -0.5802],\n",
      "          [-0.5802, -0.5802, -0.5802,  ..., -0.5802, -0.5802, -0.5802],\n",
      "          ...,\n",
      "          [-0.5802, -0.5802, -0.5802,  ..., -0.5802, -0.5802, -0.5802],\n",
      "          [-0.5802, -0.5802, -0.5802,  ..., -0.5802, -0.5802, -0.5802],\n",
      "          [-0.5802, -0.5802, -0.5802,  ..., -0.5802, -0.5802, -0.5802]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3428,  0.3428,  0.3428,  ...,  0.3428,  0.3428,  0.3428],\n",
      "          [ 0.3428,  0.3428,  0.3428,  ...,  0.3428,  0.3428,  0.3428],\n",
      "          [ 0.3428,  0.3428,  0.3428,  ...,  0.3428,  0.3428,  0.3428],\n",
      "          ...,\n",
      "          [ 0.3428,  0.3428,  0.3428,  ...,  0.3428,  0.3428,  0.3428],\n",
      "          [ 0.3428,  0.3428,  0.3428,  ...,  0.3428,  0.3428,  0.3428],\n",
      "          [ 0.3428,  0.3428,  0.3428,  ...,  0.3428,  0.3428,  0.3428]],\n",
      "\n",
      "         [[ 0.8945,  0.8945,  0.8945,  ...,  0.8945,  0.8945,  0.8945],\n",
      "          [ 0.8945,  0.8945,  0.8945,  ...,  0.8945,  0.8945,  0.8945],\n",
      "          [ 0.8945,  0.8945,  0.8945,  ...,  0.8945,  0.8945,  0.8945],\n",
      "          ...,\n",
      "          [ 0.8945,  0.8945,  0.8945,  ...,  0.8945,  0.8945,  0.8945],\n",
      "          [ 0.8945,  0.8945,  0.8945,  ...,  0.8945,  0.8945,  0.8945],\n",
      "          [ 0.8945,  0.8945,  0.8945,  ...,  0.8945,  0.8945,  0.8945]],\n",
      "\n",
      "         [[ 0.5881,  0.5881,  0.5881,  ...,  0.5881,  0.5881,  0.5881],\n",
      "          [ 0.5881,  0.5881,  0.5881,  ...,  0.5881,  0.5881,  0.5881],\n",
      "          [ 0.5881,  0.5881,  0.5881,  ...,  0.5881,  0.5881,  0.5881],\n",
      "          ...,\n",
      "          [ 0.5881,  0.5881,  0.5881,  ...,  0.5881,  0.5881,  0.5881],\n",
      "          [ 0.5881,  0.5881,  0.5881,  ...,  0.5881,  0.5881,  0.5881],\n",
      "          [ 0.5881,  0.5881,  0.5881,  ...,  0.5881,  0.5881,  0.5881]]]])\n"
     ]
    }
   ],
   "source": [
    "# Исходный тензор с формой (10, 3, 1, 1)\n",
    "expanded_param = torch.randn(10, 3, 1, 1)\n",
    "\n",
    "# Расширяем до (10, 3, 240, 240)\n",
    "result = expanded_param.expand(-1, -1, 240, 240)\n",
    "\n",
    "print(\"Исходная форма:\", expanded_param)  # torch.Size([10, 3, 1, 1])\n",
    "print(\"Новая форма:\", result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
